{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADmIN\\AppData\\Local\\Temp\\ipykernel_8528\\1328943546.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Load & preprocess\n",
    "df = pd.read_csv('titanic.csv')\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "X = df[['Pclass', 'Age', 'Sex']]\n",
    "y = df['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Accuracy: 0.78,Precision: 0.76, Recall: 0.68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\\nrf_model.fit(X_train, y_train)\\ny_pred_rf = rf_model.predict(X_test)\\n#BAGGING CLASSIFIER\\nbag_model = BaggingClassifier(estimator=DecisionTreeClassifier(),\\n                               n_estimators=50, random_state=42)\\nbag_model.fit(X_train, y_train)\\ny_pred_bag = bag_model.predict(X_test)\\n#GRADIENT BOOSTING\\ngb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\\ngb_model.fit(X_train, y_train)\\ny_pred_gb = gb_model.predict(X_test)\\nestimators = [   #STACKING\\n    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\\n    ('dt', DecisionTreeClassifier())]\\nstack_model = StackingClassifier(estimators=estimators,\\n                                  final_estimator=LogisticRegression())\\nstack_model.fit(X_train, y_train)\\ny_pred_stack = stack_model.predict(X_test)\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the Decision Tree Classifier\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "# Calculate metrics , same for all\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree - Accuracy: {accuracy_dt:.2f},Precision: {precision_dt:.2f}, Recall: {recall_dt:.2f}\")\n",
    "#RANDOM FOREST\n",
    "'''rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "#BAGGING CLASSIFIER\n",
    "bag_model = BaggingClassifier(estimator=DecisionTreeClassifier(),\n",
    "                               n_estimators=50, random_state=42)\n",
    "bag_model.fit(X_train, y_train)\n",
    "y_pred_bag = bag_model.predict(X_test)\n",
    "#GRADIENT BOOSTING\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "estimators = [   #STACKING\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier())]\n",
    "stack_model = StackingClassifier(estimators=estimators,\n",
    "                                  final_estimator=LogisticRegression())\n",
    "stack_model.fit(X_train, y_train)\n",
    "y_pred_stack = stack_model.predict(X_test)'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Accuracy: 0.79, Precision: 0.78, Recall: 0.70\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest - Accuracy: {accuracy_rf:.2f}, Precision: {precision_rf:.2f}, Recall: {recall_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging - Accuracy: 0.79, Precision: 0.76, Recall: 0.70\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train Bagging Classifier\n",
    "bag_model = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "bag_model.fit(X_train, y_train)\n",
    "y_pred_bag = bag_model.predict(X_test)\n",
    "\n",
    "accuracy_bag = accuracy_score(y_test, y_pred_bag)\n",
    "precision_bag = precision_score(y_test, y_pred_bag)\n",
    "recall_bag = recall_score(y_test, y_pred_bag)\n",
    "\n",
    "print(f\"Bagging - Accuracy: {accuracy_bag:.2f}, Precision: {precision_bag:.2f}, Recall: {recall_bag:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting (e.g., AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost - Accuracy: 0.80, Precision: 0.78, Recall: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADmIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ada_model = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "ada_model.fit(X_train, y_train)\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "\n",
    "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
    "precision_ada = precision_score(y_test, y_pred_ada)\n",
    "recall_ada = recall_score(y_test, y_pred_ada)\n",
    "\n",
    "print(f\"AdaBoost - Accuracy: {accuracy_ada:.2f}, Precision: {precision_ada:.2f}, Recall: {recall_ada:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Accuracy: 0.81, Precision: 0.83, Recall: 0.68\n"
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "accuracy_gb = accuracy_score(y_test, y_pred_gb)\n",
    "precision_gb = precision_score(y_test, y_pred_gb)\n",
    "recall_gb = recall_score(y_test, y_pred_gb)\n",
    "\n",
    "print(f\"Gradient Boosting - Accuracy: {accuracy_gb:.2f}, Precision: {precision_gb:.2f}, Recall: {recall_gb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking - Accuracy: 0.79, Precision: 0.78, Recall: 0.70\n"
     ]
    }
   ],
   "source": [
    "estimators = [\n",
    "    ('rf', RandomForestClassifier(n_estimators=50, random_state=42)),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "]\n",
    "stack_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stack_model.fit(X_train, y_train)\n",
    "y_pred_stack = stack_model.predict(X_test)\n",
    "\n",
    "accuracy_stack = accuracy_score(y_test, y_pred_stack)\n",
    "precision_stack = precision_score(y_test, y_pred_stack)\n",
    "recall_stack = recall_score(y_test, y_pred_stack)\n",
    "\n",
    "print(f\"Stacking - Accuracy: {accuracy_stack:.2f}, Precision: {precision_stack:.2f}, Recall: {recall_stack:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model  Accuracy  Precision    Recall\n",
      "0      Decision Tree  0.776536   0.757576  0.675676\n",
      "1      Random Forest  0.793296   0.776119  0.702703\n",
      "2            Bagging  0.787709   0.764706  0.702703\n",
      "3           AdaBoost  0.804469   0.782609  0.729730\n",
      "4  Gradient Boosting  0.810056   0.833333  0.675676\n",
      "5           Stacking  0.793296   0.776119  0.702703\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the calculated metrics for each model\n",
    "comparison_table = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'Random Forest', 'Bagging', 'AdaBoost', 'Gradient Boosting', 'Stacking'],\n",
    "    'Accuracy': [accuracy_dt, accuracy_rf, accuracy_bag, accuracy_ada, accuracy_gb, accuracy_stack],\n",
    "    'Precision': [precision_dt, precision_rf, precision_bag, precision_ada, precision_gb, precision_stack],\n",
    "    'Recall': [recall_dt, recall_rf, recall_bag, recall_ada, recall_gb, recall_stack]\n",
    "})\n",
    "\n",
    "print(comparison_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
